{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <font color=\"#483D8B\">\n",
    "<h1  align=\"center\">Ensemble Learning Methods using H2O</h1>\n",
    "<h3 align=\"center\"> Ansh Sikka</h3>\n",
    "<h3 align=\"center\"> 03/12/2018</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### Goals\n",
    "* Improve Model Performance with Ensemble Learning\n",
    "* Use a special boosting algorithm that improves model performance and reduces bias\n",
    "\n",
    "### Skills\n",
    "* Implement xgboost into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
      "Warning: Your H2O cluster version is too old (1 year and 19 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>15 days 5 hours 35 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.18.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 year and 19 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_anshikka_b6rz2z</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.223 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         15 days 5 hours 35 mins\n",
       "H2O cluster timezone:       America/Chicago\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.18.0.2\n",
       "H2O cluster version age:    1 year and 19 days !!!\n",
       "H2O cluster name:           H2O_from_python_anshikka_b6rz2z\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.223 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.8 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import h2o\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "We will be using the agaricus dataset. \n",
    "\n",
    "For our classifier without boosting, we will be using the CSV from https://www.kaggle.com/uciml/mushroom-classification\n",
    "\n",
    "* C1: classedible=e, poisonous=p\n",
    "* C2: cap-shapebell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "* C3: cap-surfacefibrous=f,grooves=g,scaly=y,smooth=s\n",
    "* C4: cap-colorbrown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "* C5: bruisesbruises=t,no=f\n",
    "* C6: odoralmond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n",
    "* C7: gill-attachmentattached=a, descending=d, free=f, notched=n\n",
    "* C8: gill-spacingclose=c,crowded=w,distant=d\n",
    "* C9: gill-sizebroad=b,narrow=n\n",
    "* C10: gill-colorblack=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "* C11: stalk-shape\n",
    "* C12: stalk-root\n",
    "* C13: stalk-surface-above-ring\n",
    "* C14: stalk-surface-below-ring\n",
    "* C15: stalk-color-above-ring\n",
    "* C16: stalk-color-below-ring\n",
    "* C17: veil-type\n",
    "* C18: veil-color\n",
    "* C19: ring-number\n",
    "* C20: ring-type\n",
    "* C21: spore-print-color\n",
    "* C22: population\n",
    "* C23: habitat\n",
    "\n",
    "\n",
    "For our classifier with XGBoost, we will be using the dataset form \n",
    "https://github.com/dmlc/xgboost/blob/master/demo/data/agaricus.txt.test\n",
    "\n",
    "The feature map is described here: https://github.com/dmlc/xgboost/blob/master/demo/data/featmap.txt#L30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "mushroom_data = h2o.import_file('mushrooms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C1',\n",
       " 'C2',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C7',\n",
       " 'C8',\n",
       " 'C9',\n",
       " 'C10',\n",
       " 'C11',\n",
       " 'C12',\n",
       " 'C13',\n",
       " 'C14',\n",
       " 'C15',\n",
       " 'C16',\n",
       " 'C17',\n",
       " 'C18',\n",
       " 'C19',\n",
       " 'C20',\n",
       " 'C21',\n",
       " 'C22',\n",
       " 'C23']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom_data.col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:8125\n",
      "Cols:23\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>C1   </th><th>C2       </th><th>C3         </th><th>C4       </th><th>C5     </th><th>C6  </th><th>C7             </th><th>C8          </th><th>C9       </th><th>C10       </th><th>C11        </th><th>C12       </th><th>C13                     </th><th>C14                     </th><th>C15                   </th><th>C16                   </th><th>C17      </th><th>C18       </th><th>C19        </th><th>C20      </th><th>C21              </th><th>C22       </th><th>C23    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum </td><td>enum     </td><td>enum       </td><td>enum     </td><td>enum   </td><td>enum</td><td>enum           </td><td>enum        </td><td>enum     </td><td>enum      </td><td>enum       </td><td>enum      </td><td>enum                    </td><td>enum                    </td><td>enum                  </td><td>enum                  </td><td>enum     </td><td>enum      </td><td>enum       </td><td>enum     </td><td>enum             </td><td>enum      </td><td>enum   </td></tr>\n",
       "<tr><td>mins   </td><td>     </td><td>         </td><td>           </td><td>         </td><td>       </td><td>    </td><td>               </td><td>            </td><td>         </td><td>          </td><td>           </td><td>          </td><td>                        </td><td>                        </td><td>                      </td><td>                      </td><td>         </td><td>          </td><td>           </td><td>         </td><td>                 </td><td>          </td><td>       </td></tr>\n",
       "<tr><td>mean   </td><td>     </td><td>         </td><td>           </td><td>         </td><td>       </td><td>    </td><td>               </td><td>            </td><td>         </td><td>          </td><td>           </td><td>          </td><td>                        </td><td>                        </td><td>                      </td><td>                      </td><td>         </td><td>          </td><td>           </td><td>         </td><td>                 </td><td>          </td><td>       </td></tr>\n",
       "<tr><td>maxs   </td><td>     </td><td>         </td><td>           </td><td>         </td><td>       </td><td>    </td><td>               </td><td>            </td><td>         </td><td>          </td><td>           </td><td>          </td><td>                        </td><td>                        </td><td>                      </td><td>                      </td><td>         </td><td>          </td><td>           </td><td>         </td><td>                 </td><td>          </td><td>       </td></tr>\n",
       "<tr><td>sigma  </td><td>     </td><td>         </td><td>           </td><td>         </td><td>       </td><td>    </td><td>               </td><td>            </td><td>         </td><td>          </td><td>           </td><td>          </td><td>                        </td><td>                        </td><td>                      </td><td>                      </td><td>         </td><td>          </td><td>           </td><td>         </td><td>                 </td><td>          </td><td>       </td></tr>\n",
       "<tr><td>zeros  </td><td>     </td><td>         </td><td>           </td><td>         </td><td>       </td><td>    </td><td>               </td><td>            </td><td>         </td><td>          </td><td>           </td><td>          </td><td>                        </td><td>                        </td><td>                      </td><td>                      </td><td>         </td><td>          </td><td>           </td><td>         </td><td>                 </td><td>          </td><td>       </td></tr>\n",
       "<tr><td>missing</td><td>0    </td><td>0        </td><td>0          </td><td>0        </td><td>0      </td><td>0   </td><td>0              </td><td>0           </td><td>0        </td><td>0         </td><td>0          </td><td>0         </td><td>0                       </td><td>0                       </td><td>0                     </td><td>0                     </td><td>0        </td><td>0         </td><td>0          </td><td>0        </td><td>0                </td><td>0         </td><td>0      </td></tr>\n",
       "<tr><td>0      </td><td>class</td><td>cap-shape</td><td>cap-surface</td><td>cap-color</td><td>bruises</td><td>odor</td><td>gill-attachment</td><td>gill-spacing</td><td>gill-size</td><td>gill-color</td><td>stalk-shape</td><td>stalk-root</td><td>stalk-surface-above-ring</td><td>stalk-surface-below-ring</td><td>stalk-color-above-ring</td><td>stalk-color-below-ring</td><td>veil-type</td><td>veil-color</td><td>ring-number</td><td>ring-type</td><td>spore-print-color</td><td>population</td><td>habitat</td></tr>\n",
       "<tr><td>1      </td><td>p    </td><td>x        </td><td>s          </td><td>n        </td><td>t      </td><td>p   </td><td>f              </td><td>c           </td><td>n        </td><td>k         </td><td>e          </td><td>e         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>p        </td><td>k                </td><td>s         </td><td>u      </td></tr>\n",
       "<tr><td>2      </td><td>e    </td><td>x        </td><td>s          </td><td>y        </td><td>t      </td><td>a   </td><td>f              </td><td>c           </td><td>b        </td><td>k         </td><td>e          </td><td>c         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>p        </td><td>n                </td><td>n         </td><td>g      </td></tr>\n",
       "<tr><td>3      </td><td>e    </td><td>b        </td><td>s          </td><td>w        </td><td>t      </td><td>l   </td><td>f              </td><td>c           </td><td>b        </td><td>n         </td><td>e          </td><td>c         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>p        </td><td>n                </td><td>n         </td><td>m      </td></tr>\n",
       "<tr><td>4      </td><td>p    </td><td>x        </td><td>y          </td><td>w        </td><td>t      </td><td>p   </td><td>f              </td><td>c           </td><td>n        </td><td>n         </td><td>e          </td><td>e         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>p        </td><td>k                </td><td>s         </td><td>u      </td></tr>\n",
       "<tr><td>5      </td><td>e    </td><td>x        </td><td>s          </td><td>g        </td><td>f      </td><td>n   </td><td>f              </td><td>w           </td><td>b        </td><td>k         </td><td>t          </td><td>e         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>e        </td><td>n                </td><td>a         </td><td>g      </td></tr>\n",
       "<tr><td>6      </td><td>e    </td><td>x        </td><td>y          </td><td>y        </td><td>t      </td><td>a   </td><td>f              </td><td>c           </td><td>b        </td><td>n         </td><td>e          </td><td>c         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>p        </td><td>k                </td><td>n         </td><td>g      </td></tr>\n",
       "<tr><td>7      </td><td>e    </td><td>b        </td><td>s          </td><td>w        </td><td>t      </td><td>a   </td><td>f              </td><td>c           </td><td>b        </td><td>g         </td><td>e          </td><td>c         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>p        </td><td>k                </td><td>n         </td><td>m      </td></tr>\n",
       "<tr><td>8      </td><td>e    </td><td>b        </td><td>y          </td><td>w        </td><td>t      </td><td>l   </td><td>f              </td><td>c           </td><td>b        </td><td>n         </td><td>e          </td><td>c         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>p        </td><td>n                </td><td>s         </td><td>m      </td></tr>\n",
       "<tr><td>9      </td><td>p    </td><td>x        </td><td>y          </td><td>w        </td><td>t      </td><td>p   </td><td>f              </td><td>c           </td><td>n        </td><td>p         </td><td>e          </td><td>e         </td><td>s                       </td><td>s                       </td><td>w                     </td><td>w                     </td><td>p        </td><td>w         </td><td>o          </td><td>p        </td><td>k                </td><td>v         </td><td>g      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mushroom_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data is all shown as letters. We have to find some way to encode this to numerical values to fit our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_data = mushroom_data.asnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:8125\n",
      "Cols:23\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>C1                 </th><th>C2                </th><th>C3                </th><th>C4                </th><th>C5                 </th><th>C6                </th><th>C7                 </th><th>C8                </th><th>C9                </th><th>C10               </th><th>C11              </th><th>C12               </th><th>C13               </th><th>C14               </th><th>C15               </th><th>C16              </th><th>C17                   </th><th>C18               </th><th>C19               </th><th>C20              </th><th>C21               </th><th>C22               </th><th>C23               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int                </td><td>int               </td><td>int               </td><td>int               </td><td>int                </td><td>int               </td><td>int                </td><td>int               </td><td>int               </td><td>int               </td><td>int              </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int              </td><td>int                   </td><td>int               </td><td>int               </td><td>int              </td><td>int               </td><td>int               </td><td>int               </td></tr>\n",
       "<tr><td>mins   </td><td>0.0                </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0                </td><td>0.0               </td><td>0.0                </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0              </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0              </td><td>0.0                   </td><td>0.0               </td><td>0.0               </td><td>0.0              </td><td>0.0               </td><td>0.0               </td><td>0.0               </td></tr>\n",
       "<tr><td>mean   </td><td>1.4818461538461538 </td><td>4.2916923076923075</td><td>2.827323076923077 </td><td>5.478153846153846 </td><td>1.415384615384616  </td><td>4.318276923076923 </td><td>0.974276923076923  </td><td>0.3230769230769231</td><td>0.6184615384615385</td><td>5.4932923076923075</td><td>1.1344           </td><td>1.1102769230769232</td><td>1.5782153846153844</td><td>1.6387692307692308</td><td>6.366892307692308 </td><td>6.337353846153846</td><td>0.00012307692307692307</td><td>2.9417846153846154</td><td>1.1433846153846154</td><td>2.292307692307692</td><td>3.902769230769231 </td><td>4.505476923076923 </td><td>1.8567384615384614</td></tr>\n",
       "<tr><td>maxs   </td><td>2.0                </td><td>6.0               </td><td>4.0               </td><td>10.0              </td><td>2.0                </td><td>9.0               </td><td>2.0                </td><td>2.0               </td><td>2.0               </td><td>12.0              </td><td>2.0              </td><td>5.0               </td><td>4.0               </td><td>4.0               </td><td>9.0               </td><td>9.0              </td><td>1.0                   </td><td>4.0               </td><td>3.0               </td><td>5.0              </td><td>9.0               </td><td>6.0               </td><td>7.0               </td></tr>\n",
       "<tr><td>sigma  </td><td>0.49994735169545135</td><td>1.7326437348774268</td><td>1.2301968653587674</td><td>2.5945292477046804</td><td>0.49306826357031086</td><td>2.3742872126615513</td><td>0.15909327214603255</td><td>0.7360154509805564</td><td>0.9243432715485954</td><td>3.9251503251698336</td><td>0.990926039895801</td><td>1.0619181221237886</td><td>0.6306960160664118</td><td>0.767122589290631 </td><td>2.2734984989575726</td><td>2.280229747004696</td><td>0.011094003924504582  </td><td>0.3890209344360002</td><td>0.5285959732993591</td><td>1.80181159284112 </td><td>2.8231822317862196</td><td>1.5539298459519368</td><td>2.150116034598863 </td></tr>\n",
       "<tr><td>zeros  </td><td>1                  </td><td>452               </td><td>1                 </td><td>168               </td><td>1                  </td><td>400               </td><td>210                </td><td>6812              </td><td>5612              </td><td>1728              </td><td>3516             </td><td>2480              </td><td>552               </td><td>600               </td><td>432               </td><td>432              </td><td>8124                  </td><td>96                </td><td>36                </td><td>2776             </td><td>48                </td><td>384               </td><td>3148              </td></tr>\n",
       "<tr><td>missing</td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                     </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                 </td><td>0                 </td><td>0                 </td></tr>\n",
       "<tr><td>0      </td><td>0.0                </td><td>2.0               </td><td>0.0               </td><td>2.0               </td><td>0.0                </td><td>6.0               </td><td>2.0                </td><td>1.0               </td><td>1.0               </td><td>3.0               </td><td>1.0              </td><td>5.0               </td><td>3.0               </td><td>3.0               </td><td>7.0               </td><td>7.0              </td><td>1.0                   </td><td>2.0               </td><td>2.0               </td><td>5.0              </td><td>6.0               </td><td>3.0               </td><td>2.0               </td></tr>\n",
       "<tr><td>1      </td><td>2.0                </td><td>6.0               </td><td>3.0               </td><td>5.0               </td><td>2.0                </td><td>7.0               </td><td>1.0                </td><td>0.0               </td><td>2.0               </td><td>5.0               </td><td>0.0              </td><td>3.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>4.0               </td><td>6.0               </td></tr>\n",
       "<tr><td>2      </td><td>1.0                </td><td>6.0               </td><td>3.0               </td><td>10.0              </td><td>2.0                </td><td>0.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>5.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>3.0               </td><td>2.0               </td><td>1.0               </td></tr>\n",
       "<tr><td>3      </td><td>1.0                </td><td>0.0               </td><td>3.0               </td><td>9.0               </td><td>2.0                </td><td>3.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>6.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>3.0               </td><td>2.0               </td><td>4.0               </td></tr>\n",
       "<tr><td>4      </td><td>2.0                </td><td>6.0               </td><td>4.0               </td><td>9.0               </td><td>2.0                </td><td>7.0               </td><td>1.0                </td><td>0.0               </td><td>2.0               </td><td>6.0               </td><td>0.0              </td><td>3.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>4.0               </td><td>6.0               </td></tr>\n",
       "<tr><td>5      </td><td>1.0                </td><td>6.0               </td><td>3.0               </td><td>4.0               </td><td>1.0                </td><td>5.0               </td><td>1.0                </td><td>2.0               </td><td>0.0               </td><td>5.0               </td><td>2.0              </td><td>3.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>0.0              </td><td>3.0               </td><td>0.0               </td><td>1.0               </td></tr>\n",
       "<tr><td>6      </td><td>1.0                </td><td>6.0               </td><td>4.0               </td><td>10.0              </td><td>2.0                </td><td>0.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>6.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>2.0               </td><td>1.0               </td></tr>\n",
       "<tr><td>7      </td><td>1.0                </td><td>0.0               </td><td>3.0               </td><td>9.0               </td><td>2.0                </td><td>0.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>2.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>2.0               </td><td>4.0               </td></tr>\n",
       "<tr><td>8      </td><td>1.0                </td><td>0.0               </td><td>4.0               </td><td>9.0               </td><td>2.0                </td><td>3.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>6.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>3.0               </td><td>4.0               </td><td>4.0               </td></tr>\n",
       "<tr><td>9      </td><td>2.0                </td><td>6.0               </td><td>4.0               </td><td>9.0               </td><td>2.0                </td><td>7.0               </td><td>1.0                </td><td>0.0               </td><td>2.0               </td><td>8.0               </td><td>0.0              </td><td>3.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>5.0               </td><td>1.0               </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mushroom_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that we are getting information about this datset! We can see that as we go down within the columns, we see that values are missing. Let's fill these in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_data = mushroom_data.fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:8125\n",
      "Cols:23\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>C1                 </th><th>C2                </th><th>C3                </th><th>C4                </th><th>C5                 </th><th>C6                </th><th>C7                 </th><th>C8                </th><th>C9                </th><th>C10               </th><th>C11              </th><th>C12               </th><th>C13               </th><th>C14               </th><th>C15               </th><th>C16              </th><th>C17                   </th><th>C18               </th><th>C19               </th><th>C20              </th><th>C21               </th><th>C22               </th><th>C23               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int                </td><td>int               </td><td>int               </td><td>int               </td><td>int                </td><td>int               </td><td>int                </td><td>int               </td><td>int               </td><td>int               </td><td>int              </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int              </td><td>int                   </td><td>int               </td><td>int               </td><td>int              </td><td>int               </td><td>int               </td><td>int               </td></tr>\n",
       "<tr><td>mins   </td><td>0.0                </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0                </td><td>0.0               </td><td>0.0                </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0              </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0              </td><td>0.0                   </td><td>0.0               </td><td>0.0               </td><td>0.0              </td><td>0.0               </td><td>0.0               </td><td>0.0               </td></tr>\n",
       "<tr><td>mean   </td><td>1.4818461538461538 </td><td>4.2916923076923075</td><td>2.827323076923077 </td><td>5.478153846153846 </td><td>1.415384615384616  </td><td>4.318276923076923 </td><td>0.974276923076923  </td><td>0.3230769230769231</td><td>0.6184615384615385</td><td>5.4932923076923075</td><td>1.1344           </td><td>1.1102769230769232</td><td>1.5782153846153844</td><td>1.6387692307692308</td><td>6.366892307692308 </td><td>6.337353846153846</td><td>0.00012307692307692307</td><td>2.9417846153846154</td><td>1.1433846153846154</td><td>2.292307692307692</td><td>3.902769230769231 </td><td>4.505476923076923 </td><td>1.8567384615384614</td></tr>\n",
       "<tr><td>maxs   </td><td>2.0                </td><td>6.0               </td><td>4.0               </td><td>10.0              </td><td>2.0                </td><td>9.0               </td><td>2.0                </td><td>2.0               </td><td>2.0               </td><td>12.0              </td><td>2.0              </td><td>5.0               </td><td>4.0               </td><td>4.0               </td><td>9.0               </td><td>9.0              </td><td>1.0                   </td><td>4.0               </td><td>3.0               </td><td>5.0              </td><td>9.0               </td><td>6.0               </td><td>7.0               </td></tr>\n",
       "<tr><td>sigma  </td><td>0.49994735169545135</td><td>1.7326437348774268</td><td>1.2301968653587674</td><td>2.5945292477046804</td><td>0.49306826357031086</td><td>2.3742872126615513</td><td>0.15909327214603255</td><td>0.7360154509805564</td><td>0.9243432715485954</td><td>3.9251503251698336</td><td>0.990926039895801</td><td>1.0619181221237886</td><td>0.6306960160664118</td><td>0.767122589290631 </td><td>2.2734984989575726</td><td>2.280229747004696</td><td>0.011094003924504582  </td><td>0.3890209344360002</td><td>0.5285959732993591</td><td>1.80181159284112 </td><td>2.8231822317862196</td><td>1.5539298459519368</td><td>2.150116034598863 </td></tr>\n",
       "<tr><td>zeros  </td><td>1                  </td><td>452               </td><td>1                 </td><td>168               </td><td>1                  </td><td>400               </td><td>210                </td><td>6812              </td><td>5612              </td><td>1728              </td><td>3516             </td><td>2480              </td><td>552               </td><td>600               </td><td>432               </td><td>432              </td><td>8124                  </td><td>96                </td><td>36                </td><td>2776             </td><td>48                </td><td>384               </td><td>3148              </td></tr>\n",
       "<tr><td>missing</td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                     </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                 </td><td>0                 </td><td>0                 </td></tr>\n",
       "<tr><td>0      </td><td>0.0                </td><td>2.0               </td><td>0.0               </td><td>2.0               </td><td>0.0                </td><td>6.0               </td><td>2.0                </td><td>1.0               </td><td>1.0               </td><td>3.0               </td><td>1.0              </td><td>5.0               </td><td>3.0               </td><td>3.0               </td><td>7.0               </td><td>7.0              </td><td>1.0                   </td><td>2.0               </td><td>2.0               </td><td>5.0              </td><td>6.0               </td><td>3.0               </td><td>2.0               </td></tr>\n",
       "<tr><td>1      </td><td>2.0                </td><td>6.0               </td><td>3.0               </td><td>5.0               </td><td>2.0                </td><td>7.0               </td><td>1.0                </td><td>0.0               </td><td>2.0               </td><td>5.0               </td><td>0.0              </td><td>3.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>4.0               </td><td>6.0               </td></tr>\n",
       "<tr><td>2      </td><td>1.0                </td><td>6.0               </td><td>3.0               </td><td>10.0              </td><td>2.0                </td><td>0.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>5.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>3.0               </td><td>2.0               </td><td>1.0               </td></tr>\n",
       "<tr><td>3      </td><td>1.0                </td><td>0.0               </td><td>3.0               </td><td>9.0               </td><td>2.0                </td><td>3.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>6.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>3.0               </td><td>2.0               </td><td>4.0               </td></tr>\n",
       "<tr><td>4      </td><td>2.0                </td><td>6.0               </td><td>4.0               </td><td>9.0               </td><td>2.0                </td><td>7.0               </td><td>1.0                </td><td>0.0               </td><td>2.0               </td><td>6.0               </td><td>0.0              </td><td>3.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>4.0               </td><td>6.0               </td></tr>\n",
       "<tr><td>5      </td><td>1.0                </td><td>6.0               </td><td>3.0               </td><td>4.0               </td><td>1.0                </td><td>5.0               </td><td>1.0                </td><td>2.0               </td><td>0.0               </td><td>5.0               </td><td>2.0              </td><td>3.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>0.0              </td><td>3.0               </td><td>0.0               </td><td>1.0               </td></tr>\n",
       "<tr><td>6      </td><td>1.0                </td><td>6.0               </td><td>4.0               </td><td>10.0              </td><td>2.0                </td><td>0.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>6.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>2.0               </td><td>1.0               </td></tr>\n",
       "<tr><td>7      </td><td>1.0                </td><td>0.0               </td><td>3.0               </td><td>9.0               </td><td>2.0                </td><td>0.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>2.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>2.0               </td><td>4.0               </td></tr>\n",
       "<tr><td>8      </td><td>1.0                </td><td>0.0               </td><td>4.0               </td><td>9.0               </td><td>2.0                </td><td>3.0               </td><td>1.0                </td><td>0.0               </td><td>0.0               </td><td>6.0               </td><td>0.0              </td><td>2.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>3.0               </td><td>4.0               </td><td>4.0               </td></tr>\n",
       "<tr><td>9      </td><td>2.0                </td><td>6.0               </td><td>4.0               </td><td>9.0               </td><td>2.0                </td><td>7.0               </td><td>1.0                </td><td>0.0               </td><td>2.0               </td><td>8.0               </td><td>0.0              </td><td>3.0               </td><td>2.0               </td><td>2.0               </td><td>8.0               </td><td>8.0              </td><td>0.0                   </td><td>3.0               </td><td>1.0               </td><td>4.0              </td><td>2.0               </td><td>5.0               </td><td>1.0               </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mushroom_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There! It looks like our data is all cleaned up! Let's fit our models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "To classify this dataset, we will use a random forest classifier since it is the most effective in reducing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = ['C2',\n",
    " 'C3',\n",
    " 'C4',\n",
    " 'C5',\n",
    " 'C6',\n",
    " 'C7',\n",
    " 'C8',\n",
    " 'C9',\n",
    " 'C10',\n",
    " 'C11',\n",
    " 'C12',\n",
    " 'C13',\n",
    " 'C14',\n",
    " 'C15',\n",
    " 'C16',\n",
    " 'C17',\n",
    " 'C18',\n",
    " 'C19',\n",
    " 'C20',\n",
    " 'C21',\n",
    " 'C22',\n",
    " 'C23']\n",
    "response_column = 'C1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mushroom_data.split_frame(ratios=[0.8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model = H2ORandomForestEstimator(binomial_double_trees=False, seed=1234)\n",
    "\n",
    "model.train(x=training_columns, y = response_column, training_frame = train, validation_frame = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_model_python_1552239155776_7\n",
      "\n",
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 1.0568919101293697e-05\n",
      "RMSE: 0.0032509874040502983\n",
      "MAE: 0.00015109927239650883\n",
      "RMSLE: 0.001340000569952506\n",
      "Mean Residual Deviance: 1.0568919101293697e-05\n",
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.0012515662650602409\n",
      "RMSE: 0.03537748245791723\n",
      "MAE: 0.000963855421686747\n",
      "RMSLE: 0.021901641223349647\n",
      "Mean Residual Deviance: 0.0012515662650602409\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_deviance</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_mae</b></td>\n",
       "<td><b>validation_deviance</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:01</td>\n",
       "<td> 0.001 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:01</td>\n",
       "<td> 0.016 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0291979</td>\n",
       "<td>0.0008525</td>\n",
       "<td>0.0008525</td>\n",
       "<td>0.0245440</td>\n",
       "<td>0.0006024</td>\n",
       "<td>0.0006024</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:01</td>\n",
       "<td> 0.025 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0179814</td>\n",
       "<td>0.0003880</td>\n",
       "<td>0.0003233</td>\n",
       "<td>0.0245440</td>\n",
       "<td>0.0006024</td>\n",
       "<td>0.0006024</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:01</td>\n",
       "<td> 0.032 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0101264</td>\n",
       "<td>0.0002051</td>\n",
       "<td>0.0001025</td>\n",
       "<td>0.0245440</td>\n",
       "<td>0.0006024</td>\n",
       "<td>0.0006024</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:01</td>\n",
       "<td> 0.039 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0081572</td>\n",
       "<td>0.0001536</td>\n",
       "<td>0.0000665</td>\n",
       "<td>0.0306800</td>\n",
       "<td>0.0007530</td>\n",
       "<td>0.0009413</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:02</td>\n",
       "<td> 0.333 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.0035527</td>\n",
       "<td>0.0001649</td>\n",
       "<td>0.0000126</td>\n",
       "<td>0.0357887</td>\n",
       "<td>0.0009822</td>\n",
       "<td>0.0012808</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:02</td>\n",
       "<td> 0.342 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.0034357</td>\n",
       "<td>0.0001599</td>\n",
       "<td>0.0000118</td>\n",
       "<td>0.0355489</td>\n",
       "<td>0.0009741</td>\n",
       "<td>0.0012637</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:02</td>\n",
       "<td> 0.351 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.0034018</td>\n",
       "<td>0.0001583</td>\n",
       "<td>0.0000116</td>\n",
       "<td>0.0358299</td>\n",
       "<td>0.0009789</td>\n",
       "<td>0.0012838</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:02</td>\n",
       "<td> 0.361 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.0033281</td>\n",
       "<td>0.0001550</td>\n",
       "<td>0.0000111</td>\n",
       "<td>0.0355991</td>\n",
       "<td>0.0009712</td>\n",
       "<td>0.0012673</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-03-25 18:09:02</td>\n",
       "<td> 0.370 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0032510</td>\n",
       "<td>0.0001511</td>\n",
       "<td>0.0000106</td>\n",
       "<td>0.0353775</td>\n",
       "<td>0.0009639</td>\n",
       "<td>0.0012516</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse          training_mae            training_deviance       validation_rmse       validation_mae         validation_deviance\n",
       "---  -------------------  ----------  -----------------  ---------------------  ----------------------  ----------------------  --------------------  ---------------------  ---------------------\n",
       "     2019-03-25 18:09:01  0.001 sec   0.0                nan                    nan                     nan                     nan                   nan                    nan\n",
       "     2019-03-25 18:09:01  0.016 sec   1.0                0.029197858123689188   0.0008525149190110827   0.0008525149190110827   0.024544034683690798  0.0006024096385542169  0.0006024096385542169\n",
       "     2019-03-25 18:09:01  0.025 sec   2.0                0.017981423995281517   0.00038799793067770304  0.00032333160889808587  0.024544034683690798  0.0006024096385542169  0.0006024096385542169\n",
       "     2019-03-25 18:09:01  0.032 sec   3.0                0.010126355123567276   0.00020508613617719443  0.00010254306808859722  0.024544034683690798  0.0006024096385542169  0.0006024096385542169\n",
       "     2019-03-25 18:09:01  0.039 sec   4.0                0.00815718881336302    0.00015355322154658803  6.653972933685481e-05   0.0306800433546135    0.0007530120481927711  0.0009412650602409639\n",
       "---  ---                  ---         ---                ---                    ---                     ---                     ---                   ---                    ---\n",
       "     2019-03-25 18:09:02  0.333 sec   46.0               0.003552661540143931   0.0001649270051287105   1.2621404018817845e-05  0.03578871628799027   0.0009821896280775278  0.00128083221354226\n",
       "     2019-03-25 18:09:02  0.342 sec   47.0               0.003435665327945371   0.0001599470074037823   1.1803796245645975e-05  0.035548895579749044  0.0009741092027685207  0.0012637239769399012\n",
       "     2019-03-25 18:09:02  0.351 sec   48.0               0.003401823500894954   0.00015831963620604049  1.1572403131241202e-05  0.03582988915921986   0.000978915662650602   0.001283780957161981\n",
       "     2019-03-25 18:09:02  0.361 sec   49.0               0.0033280865982539504  0.0001549662236343796   1.107616040547755e-05   0.035599062435518476  0.0009712318662404723  0.0012672932462879426\n",
       "     2019-03-25 18:09:02  0.370 sec   50.0               0.0032509874040502983  0.00015109927239650883  1.0568919101293697e-05  0.03537748245791723   0.000963855421686747   0.0012515662650602409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C10</td>\n",
       "<td>12272.4550781</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2047594</td></tr>\n",
       "<tr><td>C6</td>\n",
       "<td>8361.2763672</td>\n",
       "<td>0.6813043</td>\n",
       "<td>0.1395034</td></tr>\n",
       "<tr><td>C9</td>\n",
       "<td>7553.1147461</td>\n",
       "<td>0.6154526</td>\n",
       "<td>0.1260197</td></tr>\n",
       "<tr><td>C21</td>\n",
       "<td>7441.625</td>\n",
       "<td>0.6063681</td>\n",
       "<td>0.1241596</td></tr>\n",
       "<tr><td>C20</td>\n",
       "<td>5244.2773438</td>\n",
       "<td>0.4273210</td>\n",
       "<td>0.0874980</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>C3</td>\n",
       "<td>442.3371887</td>\n",
       "<td>0.0360431</td>\n",
       "<td>0.0073802</td></tr>\n",
       "<tr><td>C4</td>\n",
       "<td>333.4078674</td>\n",
       "<td>0.0271672</td>\n",
       "<td>0.0055627</td></tr>\n",
       "<tr><td>C18</td>\n",
       "<td>103.2932587</td>\n",
       "<td>0.0084167</td>\n",
       "<td>0.0017234</td></tr>\n",
       "<tr><td>C2</td>\n",
       "<td>81.2456055</td>\n",
       "<td>0.0066202</td>\n",
       "<td>0.0013555</td></tr>\n",
       "<tr><td>C7</td>\n",
       "<td>72.5256195</td>\n",
       "<td>0.0059096</td>\n",
       "<td>0.0012101</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance      percentage\n",
       "----------  ---------------------  ---------------------  ---------------------\n",
       "C10         12272.455078125        1.0                    0.20475938369614025\n",
       "C6          8361.2763671875        0.6813042959995047     0.1395034477583913\n",
       "C9          7553.11474609375       0.615452629324085      0.1260197010745687\n",
       "C21         7441.625               0.606368078157752      0.12415955397659428\n",
       "C20         5244.27734375          0.4273209647430404     0.08749797738122501\n",
       "---         ---                    ---                    ---\n",
       "C3          442.3371887207031      0.036043088844476254   0.007380160658300185\n",
       "C4          333.4078674316406      0.027167169511658873   0.005562732885975842\n",
       "C18         103.29325866699219     0.008416674415138577   0.0017233930660148465\n",
       "C2          81.24560546875         0.0066201591247676255  0.0013555397023577982\n",
       "C7          72.52561950683594      0.00590962599130707    0.0012100513758547275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.0012515662650602409\n",
      "RMSE: 0.03537748245791723\n",
      "MAE: 0.000963855421686747\n",
      "RMSLE: 0.021901641223349647\n",
      "Mean Residual Deviance: 0.0012515662650602409\n",
      "\n",
      "Model Type: regressor\n",
      "R2 0.9949950717183972\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C10</td>\n",
       "<td>12272.4550781</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2047594</td></tr>\n",
       "<tr><td>C6</td>\n",
       "<td>8361.2763672</td>\n",
       "<td>0.6813043</td>\n",
       "<td>0.1395034</td></tr>\n",
       "<tr><td>C9</td>\n",
       "<td>7553.1147461</td>\n",
       "<td>0.6154526</td>\n",
       "<td>0.1260197</td></tr>\n",
       "<tr><td>C21</td>\n",
       "<td>7441.625</td>\n",
       "<td>0.6063681</td>\n",
       "<td>0.1241596</td></tr>\n",
       "<tr><td>C20</td>\n",
       "<td>5244.2773438</td>\n",
       "<td>0.4273210</td>\n",
       "<td>0.0874980</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>C3</td>\n",
       "<td>442.3371887</td>\n",
       "<td>0.0360431</td>\n",
       "<td>0.0073802</td></tr>\n",
       "<tr><td>C4</td>\n",
       "<td>333.4078674</td>\n",
       "<td>0.0271672</td>\n",
       "<td>0.0055627</td></tr>\n",
       "<tr><td>C18</td>\n",
       "<td>103.2932587</td>\n",
       "<td>0.0084167</td>\n",
       "<td>0.0017234</td></tr>\n",
       "<tr><td>C2</td>\n",
       "<td>81.2456055</td>\n",
       "<td>0.0066202</td>\n",
       "<td>0.0013555</td></tr>\n",
       "<tr><td>C7</td>\n",
       "<td>72.5256195</td>\n",
       "<td>0.0059096</td>\n",
       "<td>0.0012101</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance      percentage\n",
       "----------  ---------------------  ---------------------  ---------------------\n",
       "C10         12272.455078125        1.0                    0.20475938369614025\n",
       "C6          8361.2763671875        0.6813042959995047     0.1395034477583913\n",
       "C9          7553.11474609375       0.615452629324085      0.1260197010745687\n",
       "C21         7441.625               0.606368078157752      0.12415955397659428\n",
       "C20         5244.27734375          0.4273209647430404     0.08749797738122501\n",
       "---         ---                    ---                    ---\n",
       "C3          442.3371887207031      0.036043088844476254   0.007380160658300185\n",
       "C4          333.4078674316406      0.027167169511658873   0.005562732885975842\n",
       "C18         103.29325866699219     0.008416674415138577   0.0017233930660148465\n",
       "C2          81.24560546875         0.0066201591247676255  0.0013555397023577982\n",
       "C7          72.52561950683594      0.00590962599130707    0.0012100513758547275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "<bound method H2OTwoDimTable.as_data_frame of >\n"
     ]
    }
   ],
   "source": [
    "performance = model.model_performance(test_data=test)\n",
    "print(model)\n",
    "print(performance)\n",
    "print('Model Type:', model.type)\n",
    "print('R2', model.r2(valid = True))\n",
    "print(model._model_json['output']['variable_importances'].as_data_frame)\n",
    "\n",
    "Overfitting if: training loss >> validation loss\n",
    "Underfitting if: training loss << validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "From this result, we can see that this model was fairly well-fitted. We see that the most important variable is C10, the gill color. This means that color is one of the most important characteristics for prediction. The mean-squared-error is very low, meaning that there was low error in predicting the test results. The R-squared score was also very close to 1, meaning that the model explains all the variablility of the response data around its mean. Let's try to reduce variance using boosint!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Classifier\n",
    "We will try our best to reduce variance and overfitting by using boosting. We will use a gradient-descent based boosting algorithm called xgboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read our data in first with the dataset that is already converted for XGBoost's model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:57] 6513x127 matrix with 143286 entries loaded from agaricus.txt.train\n",
      "[23:16:57] 1611x127 matrix with 35442 entries loaded from agaricus.txt.test\n",
      "[0. 1. 0. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix('agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('agaricus.txt.test')\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "test_data = load_svmlight_file('agaricus.txt.test')[1]\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "num_round = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-error:0.042831\ttrain-error:0.046522\n",
      "[1]\teval-error:0.021726\ttrain-error:0.022263\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(dtest,'eval'), (dtrain,'train')]\n",
    "\n",
    "evals_result = {}\n",
    "xg_boost_model = xgb.train(param, dtrain, num_round, watchlist, evals_result=evals_result)\n",
    "preds = xg_boost_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(prediction) for prediction in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a26b1fa58>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xg_boost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.DMatrix object at 0x1a26b0a160>\n"
     ]
    }
   ],
   "source": [
    "print(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129807395518242"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(test_data, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "We see that this R^2 is a little lower. Why is this? Well, this time we are boosting and reducing variance, so the model will inheritly not overfit the data. This R^2 is still really high based on the data. However, there might be a little more bias this time in the data, as boosting does NOT target bias. For the feature importance, f29 is the odor, which is also a big characteristic in mushrooms. This feature importance graph doesn't consider gill color. RandomForest model probably assumed that the color is a major deciding factor when splitting decisions. However, it probably only is for THAT dataset. This one will generalize the features and look at it by reducing overfitting overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "What I learned:\n",
    "* RandomForest Classification Review (Using H2O)\n",
    "* XGBoost\n",
    "    * XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and      portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples. (See https://xgboost.readthedocs.io/en/latest/)\n",
    "\n",
    "As we can see, the random forest classifier DID have a higher R^2 score. However, we didn't apply any variance reduction technique to the model. The data could have been a little more overfit and more specific to the dataset we trained. This model uses gradient descent algorithm to build smaller trees and essentially limits all of the factors that are increasing variance/covariance. This will reduce the R^2 score, but will also be more general to external datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
